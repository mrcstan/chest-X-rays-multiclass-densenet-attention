{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select a Subset of Images for Training, Validation and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from os import walk\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"./labels\"\n",
    "\n",
    "# approximate target number of images for each disease\n",
    "# if number of images available < NUM_ITEM_PER_CAT for a disease,\n",
    "# all images associated with that disease will be selected\n",
    "NUM_ITEM_PER_CAT = 2000\n",
    "\n",
    "# target number of images for the no finding class\n",
    "NUM_ITEM_NO_FINDING = 10000\n",
    "\n",
    "# Approximate percentage of the validation images in \n",
    "# the training-validation dataset\n",
    "PERCENT_VAL = 0.1\n",
    "N_SPLITS = 3; # no. of training-validation splits\n",
    "\n",
    "# Name of the training-validation file\n",
    "OUT_TRAIN_VAL_LIST = 'train_val_B.csv'\n",
    "# Prefix for the training and validation files \n",
    "# The split number will be added to the prefix followed by .csv\n",
    "OUT_TRAIN_LIST_PREFIX = 'train_B'\n",
    "OUT_VAL_LIST_PREFIX = 'val_B'\n",
    "\n",
    "OUT_TEST_LIST = 'test_B.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load csv file containing image labels and other details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000001_000.png</td>\n",
       "      <td>Cardiomegaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000001_001.png</td>\n",
       "      <td>Cardiomegaly|Emphysema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000001_002.png</td>\n",
       "      <td>Cardiomegaly|Effusion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000002_000.png</td>\n",
       "      <td>No Finding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000003_001.png</td>\n",
       "      <td>Hernia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Image                  Labels\n",
       "0  00000001_000.png            Cardiomegaly\n",
       "1  00000001_001.png  Cardiomegaly|Emphysema\n",
       "2  00000001_002.png   Cardiomegaly|Effusion\n",
       "3  00000002_000.png              No Finding\n",
       "4  00000003_001.png                  Hernia"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_all = pd.read_csv(BASE_PATH + '/Data_Entry_2017_v2020.csv')\n",
    "dat_all = dat_all[['Image Index', 'Finding Labels']]\n",
    "dat_all.rename(columns={'Image Index': 'Image', 'Finding Labels': 'Labels'}, inplace=True)\n",
    "dat_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get frequency for each disease class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Hernia': 227, 'Pneumonia': 1431, 'Fibrosis': 1686, 'Edema': 2303, 'Emphysema': 2516, 'Cardiomegaly': 2776, 'Pleural_Thickening': 3385, 'Consolidation': 4667, 'Pneumothorax': 5302, 'Mass': 5782, 'Nodule': 6331, 'Atelectasis': 11559, 'Effusion': 13317, 'Infiltration': 19894, 'No Finding': 60361}\n",
      "                   Image                  Labels  No Finding  Cardiomegaly  \\\n",
      "0       00000001_000.png            Cardiomegaly           0             1   \n",
      "1       00000001_001.png  Cardiomegaly|Emphysema           0             1   \n",
      "2       00000001_002.png   Cardiomegaly|Effusion           0             1   \n",
      "3       00000002_000.png              No Finding           1             0   \n",
      "4       00000003_001.png                  Hernia           0             0   \n",
      "...                  ...                     ...         ...           ...   \n",
      "112115  00030801_001.png          Mass|Pneumonia           0             0   \n",
      "112116  00030802_000.png              No Finding           1             0   \n",
      "112117  00030803_000.png              No Finding           1             0   \n",
      "112118  00030804_000.png              No Finding           1             0   \n",
      "112119  00030805_000.png              No Finding           1             0   \n",
      "\n",
      "        Emphysema  Effusion  Hernia  Infiltration  Mass  Nodule  Atelectasis  \\\n",
      "0               0         0       0             0     0       0            0   \n",
      "1               1         0       0             0     0       0            0   \n",
      "2               0         1       0             0     0       0            0   \n",
      "3               0         0       0             0     0       0            0   \n",
      "4               0         0       1             0     0       0            0   \n",
      "...           ...       ...     ...           ...   ...     ...          ...   \n",
      "112115          0         0       0             0     1       0            0   \n",
      "112116          0         0       0             0     0       0            0   \n",
      "112117          0         0       0             0     0       0            0   \n",
      "112118          0         0       0             0     0       0            0   \n",
      "112119          0         0       0             0     0       0            0   \n",
      "\n",
      "        Pneumothorax  Pleural_Thickening  Pneumonia  Fibrosis  Edema  \\\n",
      "0                  0                   0          0         0      0   \n",
      "1                  0                   0          0         0      0   \n",
      "2                  0                   0          0         0      0   \n",
      "3                  0                   0          0         0      0   \n",
      "4                  0                   0          0         0      0   \n",
      "...              ...                 ...        ...       ...    ...   \n",
      "112115             0                   0          1         0      0   \n",
      "112116             0                   0          0         0      0   \n",
      "112117             0                   0          0         0      0   \n",
      "112118             0                   0          0         0      0   \n",
      "112119             0                   0          0         0      0   \n",
      "\n",
      "        Consolidation  num_disease  \n",
      "0                   0            1  \n",
      "1                   0            2  \n",
      "2                   0            2  \n",
      "3                   0            1  \n",
      "4                   0            1  \n",
      "...               ...          ...  \n",
      "112115              0            2  \n",
      "112116              0            1  \n",
      "112117              0            1  \n",
      "112118              0            1  \n",
      "112119              0            1  \n",
      "\n",
      "[112120 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "labels = ['No Finding', 'Cardiomegaly', 'Emphysema', 'Effusion', 'Hernia', 'Infiltration', 'Mass', 'Nodule', \n",
    "          'Atelectasis', 'Pneumothorax', 'Pleural_Thickening', 'Pneumonia', 'Fibrosis', 'Edema', 'Consolidation']\n",
    "#labels = ['No Finding', 'Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration',\n",
    "#          'Mass', 'Nodule', 'Pneumonia', 'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema',\n",
    "#          'Fibrosis', 'Pleural_Thickening', 'Hernia']\n",
    "\n",
    "def label_stats(dat_all, labels):\n",
    "\n",
    "    label_freq = dict(zip(labels, len(labels)*[0]))\n",
    "\n",
    "    for label in labels:\n",
    "        dat_all[label] = (dat_all['Labels'].str.contains(label)).astype('int32')\n",
    "        label_freq[label] = dat_all[label].sum()\n",
    "\n",
    "    dat_all['num_disease'] = dat_all[labels].sum(axis=1)\n",
    "    # Sort the single-class disease labels by frequency from lowest to highest\n",
    "    label_freq =  {k: v for k, v in sorted(label_freq.items(), key=lambda item: item[1])}\n",
    "    return dat_all, label_freq\n",
    "\n",
    "dat_all, label_freq = label_stats(dat_all, labels)\n",
    "\n",
    "print(label_freq)\n",
    "print(dat_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select subset of all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After subset select, original minimum string label count =  1\n",
      "After eliminating rows with low string label count, min string label count =  6\n",
      "Single class count: \n",
      "No Finding            10000\n",
      "Cardiomegaly           1835\n",
      "Emphysema              1841\n",
      "Effusion               2651\n",
      "Hernia                  167\n",
      "Infiltration           3124\n",
      "Mass                   1739\n",
      "Nodule                 1679\n",
      "Atelectasis            1760\n",
      "Pneumothorax           1806\n",
      "Pleural_Thickening     1837\n",
      "Pneumonia              1225\n",
      "Fibrosis               1532\n",
      "Edema                  1838\n",
      "dtype: int64\n",
      "Number of selected rows =  23630\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Labels</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Emphysema</th>\n",
       "      <th>Effusion</th>\n",
       "      <th>Hernia</th>\n",
       "      <th>Infiltration</th>\n",
       "      <th>Mass</th>\n",
       "      <th>Nodule</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Pleural_Thickening</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Fibrosis</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Consolidation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000001_001.png</td>\n",
       "      <td>Cardiomegaly|Emphysema</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000001_002.png</td>\n",
       "      <td>Cardiomegaly|Effusion</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000003_001.png</td>\n",
       "      <td>Hernia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000003_002.png</td>\n",
       "      <td>Hernia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000003_003.png</td>\n",
       "      <td>Hernia|Infiltration</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Image                  Labels  No Finding  Cardiomegaly  \\\n",
       "0  00000001_001.png  Cardiomegaly|Emphysema           0             1   \n",
       "1  00000001_002.png   Cardiomegaly|Effusion           0             1   \n",
       "2  00000003_001.png                  Hernia           0             0   \n",
       "3  00000003_002.png                  Hernia           0             0   \n",
       "4  00000003_003.png     Hernia|Infiltration           0             0   \n",
       "\n",
       "   Emphysema  Effusion  Hernia  Infiltration  Mass  Nodule  Atelectasis  \\\n",
       "0          1         0       0             0     0       0            0   \n",
       "1          0         1       0             0     0       0            0   \n",
       "2          0         0       1             0     0       0            0   \n",
       "3          0         0       1             0     0       0            0   \n",
       "4          0         0       1             1     0       0            0   \n",
       "\n",
       "   Pneumothorax  Pleural_Thickening  Pneumonia  Fibrosis  Edema  Consolidation  \n",
       "0             0                   0          0         0      0              0  \n",
       "1             0                   0          0         0      0              0  \n",
       "2             0                   0          0         0      0              0  \n",
       "3             0                   0          0         0      0              0  \n",
       "4             0                   0          0         0      0              0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 0\n",
    "min_count = NUM_ITEM_PER_CAT; # target number of images\n",
    "dat_all['Selected'] = False\n",
    "# Select the rows in the order of lowest single disease class frequency to highest\n",
    "for key, value in label_freq.items():\n",
    "    if value < min_count:\n",
    "        # Grab all rows associated with a label if the count associated \n",
    "        # with the label is less than min_count\n",
    "        dat_all.loc[dat_all[key] == 1, 'Selected'] = True\n",
    "    else:\n",
    "        # Calculate number of already selected rows with label = key\n",
    "        dat_all1 = dat_all.loc[(dat_all['Selected']) & (dat_all[key]==1)]\n",
    "        cur_label_count = dat_all1[key].sum(axis = 0)\n",
    "        deficit = min_count - cur_label_count\n",
    "        if deficit > 0:\n",
    "            # Get the rows with label = key and that have not been selected\n",
    "            dat_all1 = dat_all.loc[(~dat_all['Selected']) & (dat_all[key]==1)]\n",
    "            sel_inds = dat_all1.sample(n=deficit, axis=0, random_state=seed).index\n",
    "            dat_all.loc[sel_inds, 'Selected'] = True\n",
    "\n",
    "# Select more rows associated with a selected class\n",
    "min_count2 = NUM_ITEM_NO_FINDING\n",
    "label2 = 'No Finding'\n",
    "dat_all1 = dat_all.loc[(dat_all['Selected']) & (dat_all[label2 ]==1)]\n",
    "cur_label_count = dat_all1[label2].sum(axis = 0)\n",
    "deficit = min_count2 - cur_label_count\n",
    "if deficit > 0:\n",
    "    # Get the rows with label = key and that have not been selected\n",
    "    dat_all1 = dat_all.loc[(~dat_all['Selected']) & (dat_all[label2]==1)]\n",
    "    sel_inds = dat_all1.sample(n=deficit, axis=0, random_state=seed).index\n",
    "    dat_all.loc[sel_inds, 'Selected'] = True\n",
    "        \n",
    "dat_selected = dat_all.loc[dat_all['Selected']].copy()\n",
    "dat_selected.drop(columns=['Selected', 'num_disease'], inplace=True)\n",
    "dat_selected.reset_index(drop=True, inplace=True)\n",
    "# Remove rows with string label count <= min_labels_count based on the column 'Labels' instead of 1-hot encoding columns\n",
    "min_labels_count = 6\n",
    "labels_count = dat_selected.groupby('Labels')['Labels'].count()\n",
    "print('After subset select, original minimum string label count = ', labels_count.min())\n",
    "\n",
    "# Get the string labels with count < min_labels_count\n",
    "def remove_rows_w_low_label_count(dat, column, min_labels_count):\n",
    "    labels_count = dat.groupby(column)[column].count()\n",
    "    labels2del = list(labels_count.index[labels_count.values < min_labels_count])\n",
    "    ind2del =  dat.index[dat['Labels'].isin(labels2del)]\n",
    "    return dat.drop(index=ind2del)\n",
    "\n",
    "dat_selected = remove_rows_w_low_label_count(dat_selected, 'Labels', min_labels_count)\n",
    "\n",
    "labels_count = dat_selected.groupby('Labels')['Labels'].count()\n",
    "print('After eliminating rows with low string label count, min string label count = ', labels_count.min())\n",
    "\n",
    "single_class_counts = dat_selected.iloc[:, 2:-1].sum(axis=0)\n",
    "print('Single class count: ')\n",
    "print(single_class_counts)\n",
    "print('Number of selected rows = ', len(dat_selected))\n",
    "dat_selected.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output combined training and validation list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original train & val data min string label count =  1\n",
      "Final train & val data min string label count =  6\n",
      "Single class count for training and validation data: \n",
      "No Finding            8306\n",
      "Cardiomegaly          1083\n",
      "Emphysema             1022\n",
      "Effusion              1554\n",
      "Hernia                 101\n",
      "Infiltration          1812\n",
      "Mass                  1130\n",
      "Nodule                1144\n",
      "Atelectasis           1122\n",
      "Pneumothorax           806\n",
      "Pleural_Thickening    1153\n",
      "Pneumonia              742\n",
      "Fibrosis              1111\n",
      "Edema                 1061\n",
      "dtype: int64\n",
      "Number of selected training rows =  16944\n"
     ]
    }
   ],
   "source": [
    "train_list0 = pd.read_csv(BASE_PATH + '/train_val_list.txt', header = None, names=['Image'])\n",
    "dat_train_val = dat_selected.loc[dat_selected['Image'].isin(train_list0['Image'].values)]\n",
    "dat_train_val.reset_index(drop=True, inplace=True)\n",
    "labels_count = dat_train_val.groupby('Labels')['Labels'].count()\n",
    "print('Original train & val data min string label count = ', labels_count.min())\n",
    "#labels_count.sort_values(ascending=True, inplace=True)\n",
    "#print(labels_count\n",
    "dat_train_val = remove_rows_w_low_label_count(dat_train_val, 'Labels', min_labels_count)\n",
    "dat_train_val.reset_index(drop=True, inplace=True)\n",
    "labels_count = dat_train_val.groupby('Labels')['Labels'].count()\n",
    "print('Final train & val data min string label count = ', labels_count.min())\n",
    "single_class_counts = dat_train_val.iloc[:, 2:-1].sum(axis=0)\n",
    "print('Single class count for training and validation data: ')\n",
    "print(single_class_counts)\n",
    "print('Number of selected training rows = ', len(dat_train_val))\n",
    "dat_train_val.to_csv(BASE_PATH + '/' + OUT_TRAIN_VAL_LIST, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform stratified split on train+validation list into separate train and validation list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Split  0\n",
      "Number of training rows =  15249\n",
      "Single class count for training data: \n",
      "No Finding            7475\n",
      "Cardiomegaly           975\n",
      "Emphysema              921\n",
      "Effusion              1395\n",
      "Hernia                  91\n",
      "Infiltration          1632\n",
      "Mass                  1017\n",
      "Nodule                1029\n",
      "Atelectasis           1008\n",
      "Pneumothorax           725\n",
      "Pleural_Thickening    1036\n",
      "Pneumonia              668\n",
      "Fibrosis               999\n",
      "Edema                  954\n",
      "dtype: int64\n",
      "Number of validation rows =  1695\n",
      "Single class count for validation data: \n",
      "No Finding            831\n",
      "Cardiomegaly          108\n",
      "Emphysema             101\n",
      "Effusion              159\n",
      "Hernia                 10\n",
      "Infiltration          180\n",
      "Mass                  113\n",
      "Nodule                115\n",
      "Atelectasis           114\n",
      "Pneumothorax           81\n",
      "Pleural_Thickening    117\n",
      "Pneumonia              74\n",
      "Fibrosis              112\n",
      "Edema                 107\n",
      "dtype: int64\n",
      "\n",
      "Split  1\n",
      "Number of training rows =  15249\n",
      "Single class count for training data: \n",
      "No Finding            7475\n",
      "Cardiomegaly           977\n",
      "Emphysema              918\n",
      "Effusion              1398\n",
      "Hernia                  91\n",
      "Infiltration          1630\n",
      "Mass                  1016\n",
      "Nodule                1028\n",
      "Atelectasis           1009\n",
      "Pneumothorax           725\n",
      "Pleural_Thickening    1037\n",
      "Pneumonia              667\n",
      "Fibrosis               999\n",
      "Edema                  956\n",
      "dtype: int64\n",
      "Number of validation rows =  1695\n",
      "Single class count for validation data: \n",
      "No Finding            831\n",
      "Cardiomegaly          106\n",
      "Emphysema             104\n",
      "Effusion              156\n",
      "Hernia                 10\n",
      "Infiltration          182\n",
      "Mass                  114\n",
      "Nodule                116\n",
      "Atelectasis           113\n",
      "Pneumothorax           81\n",
      "Pleural_Thickening    116\n",
      "Pneumonia              75\n",
      "Fibrosis              112\n",
      "Edema                 105\n",
      "dtype: int64\n",
      "\n",
      "Split  2\n",
      "Number of training rows =  15249\n",
      "Single class count for training data: \n",
      "No Finding            7475\n",
      "Cardiomegaly           975\n",
      "Emphysema              918\n",
      "Effusion              1396\n",
      "Hernia                  91\n",
      "Infiltration          1633\n",
      "Mass                  1015\n",
      "Nodule                1028\n",
      "Atelectasis           1010\n",
      "Pneumothorax           726\n",
      "Pleural_Thickening    1038\n",
      "Pneumonia              669\n",
      "Fibrosis               999\n",
      "Edema                  955\n",
      "dtype: int64\n",
      "Number of validation rows =  1695\n",
      "Single class count for validation data: \n",
      "No Finding            831\n",
      "Cardiomegaly          108\n",
      "Emphysema             104\n",
      "Effusion              158\n",
      "Hernia                 10\n",
      "Infiltration          179\n",
      "Mass                  115\n",
      "Nodule                116\n",
      "Atelectasis           112\n",
      "Pneumothorax           80\n",
      "Pleural_Thickening    115\n",
      "Pneumonia              73\n",
      "Fibrosis              112\n",
      "Edema                 106\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Split training validation list into training and validation sets\n",
    "val_frac = PERCENT_VAL; # fraction of data assigned to validation set\n",
    "n_splits = N_SPLITS\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits=n_splits, test_size=val_frac, random_state=seed)\n",
    "X = np.random.rand(len(dat_train_val['Labels']))\n",
    "dat_train = []\n",
    "dat_val = []\n",
    "for split_count, (ind1, ind2) in enumerate(sss.split(X, dat_train_val['Labels'])):\n",
    "    print('\\nSplit ', split_count)\n",
    "    #print('Training set indices = ', ind1)\n",
    "    dat_train.append(dat_train_val.iloc[ind1])\n",
    "    #print(dat_train[split_count].head())\n",
    "    print('Number of training rows = ', len(dat_train[split_count]))\n",
    "    single_class_counts = dat_train[split_count].iloc[:, 2:-1].sum(axis=0)\n",
    "    print('Single class count for training data: ')\n",
    "    print(single_class_counts)\n",
    "    \n",
    "    dat_train[split_count].to_csv(BASE_PATH + '/' + OUT_TRAIN_LIST_PREFIX + '_' + str(split_count) + '.csv',\n",
    "                                 index=False)\n",
    "    \n",
    "    #print('Validation set indices = ', ind2)\n",
    "    dat_val.append(dat_train_val.iloc[ind2])\n",
    "    print('Number of validation rows = ', len(dat_val[split_count]))\n",
    "    dat_val[split_count].to_csv(BASE_PATH + '/' + OUT_VAL_LIST_PREFIX  + '_' + str(split_count) + '.csv',\n",
    "                                index=False)\n",
    "    #print(dat_val[split_count].head())\n",
    "    single_class_counts = dat_val[split_count].iloc[:, 2:-1].sum(axis=0)\n",
    "    print('Single class count for validation data: ')\n",
    "    print(single_class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output test list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test data min string label count =  1\n",
      "Final test data min string label count =  6\n",
      "Single class count: \n",
      "No Finding            1694\n",
      "Cardiomegaly           630\n",
      "Emphysema              753\n",
      "Effusion               857\n",
      "Hernia                  52\n",
      "Infiltration          1065\n",
      "Mass                   423\n",
      "Nodule                 381\n",
      "Atelectasis            498\n",
      "Pneumothorax           874\n",
      "Pleural_Thickening     536\n",
      "Pneumonia              411\n",
      "Fibrosis               327\n",
      "Edema                  698\n",
      "dtype: int64\n",
      "Number of selected testing rows =  6112\n"
     ]
    }
   ],
   "source": [
    "test_list0 = pd.read_csv(BASE_PATH + '/test_list.txt', header = None, names=['Image'])\n",
    "dat_test = dat_selected.loc[dat_selected['Image'].isin(test_list0['Image'].values)]\n",
    "labels_count = dat_test.groupby('Labels')['Labels'].count()\n",
    "print('\\nTest data min string label count = ', labels_count.min())\n",
    "dat_test = remove_rows_w_low_label_count(dat_test, 'Labels', min_labels_count)\n",
    "labels_count = dat_train_val.groupby('Labels')['Labels'].count()\n",
    "print('Final test data min string label count = ', labels_count.min())\n",
    "single_class_counts = dat_test.iloc[:, 2:-1].sum(axis=0)\n",
    "print('Single class count: ')\n",
    "print(single_class_counts)\n",
    "print('Number of selected testing rows = ', len(dat_test))\n",
    "dat_test.to_csv(BASE_PATH + '/' + OUT_TEST_LIST, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
